# dataprocAutomationAirflow
This repository showcases orchestrating dataproc cluster creation, running pyspark job where it reads data, performs transformation, storing data into GCS, then deleting cluster using Apache Airflow.
